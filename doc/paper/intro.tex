\section{Introduction}
\label{sec:introduction}

Mobile phones nowadays no longer just a ``phone''. They are supporting a more diverse set of services including Internet access, gaming console, personal area hubs, photography, etc. Also more powerful sensors, such as GPS, accelerometer, gyroscope, compass, light sensor, proximity sensor, barometer, are integrated to mobile phones. What's more, the increasing computing power. According to NASA, \studyquote{your cell phone has more computing power than the computers used during the Apollo era}. These changes have made mobile phones, the always-available devices, become the central hub for human to interact with the rest of the world. And we are seeing more development along the line. For example, Google's Project Tango\footnote{https://www.google.com/atap/projecttango/} has designed a phone that comes with motion tracking camera, depth sensor, 2x computer vision processors to push the boundary of vision-based applications on mobile phones.

Among all the exciting new applications enabled by the advance of mobile phone platforms, there is a set of applications known as {\bf Quantified Self (QS)}\cite{wolf2010quantified}. People are continuously acquiring data that can be used to assess a person's daily life. Examples of such data includes food consumed, quality of surrounding air, mood, daily activity, location history. Though we are still far from automatically collecting all the data (most applications require manual input for food consumed and mood), new technologies and data mining algorithms are being developed to leverage existing sensor data to infer meaningful events that human can understand. For example, logging the raw accelerometer data is not useful unless the data are parsed, analyzed and used in applications like games or activity logging. The the process of ``parse, analyze, infer'' is where many statistical inference algorithms can help in broadening the application scope. In this project, we are interested in the activity recognition application that recognizes a humna's physical activity from the sensors available on mobile phones. Previous work \cite{ravi2005activity, kwapisz2011activity, lee2011activity} have studied such topic and there exist many commercial applications (such as Moves\footnote{Moves, http://www.moves-app.com/}). One observation that we have is that mobile phones, given their pervasiveness, can be placed at arbitrary position and orientation throughout normal uses. On the other hand, the emerging wearable computing devices, such as Google Glass, Pebble Smartwatch, Samsung Gear, FitBit, Qualcomm Toq, are offering new opportunities for activity recognition because of their unique position on human body. Their positions add another dimension for the activity inference problem and we seek to make a comparison among them in this project and quantify the difference.

Though there are a wide choice of wearable computing platform to use, we choose Google Glass, Pebble Smartwatch as case study for this project because of their accessibility (the authors happen to have them in hand). We use another Android smart phone -- Samsung Galaxy S II, for the mobile phone data collection. To proceed, we first wrote two data collection program for both Android platform (for Android phones and Google Glass) and Pebble platform (for Pebble Smartwatch). To be succinct and without introducing ambiguity, throughout this paper, we will we use {\em Phone} for mobile phones, and {\em Glass}, {\em Pebble} for Google Glass and Pebble Smartwatch, respetively. 

We then perform a series of actions (including standing, walking, running, climbing upstairs, climbing downstairs) and use our application to collect traces of data. A video is taken to obtain the ground truth. For this report, we are using two datasets that were collected at Soda Hall, Berkeley on May 10th. One is used for training, and the other as test set. Exploratary data analysis (EDA) is performed first, followed by feature extraction and classification using logistic regression (LR) and hidden markov-model (HMM). We have found out that Glass has the best prediction among these devices; Phone is not reliable for cross-dataset test; Pebble's performance is acceptable and it's best for identifying \texttt{running} activity because of the huge arm movement.

In short, we made the following efforts in this report:
\begin{itemize}
\item We have implemented data collection applications on both Android platform and Pebble platform, and used them to collect two traces of accelerometer data for activity recognition task.
\item We present the preliminary EDA on the raw data trace and investigate possible features that can be used for the activity classification.
\item We use logistic regression and hidden markov model as two main algorithms to quantify the classification performance on our dataset.
\end{itemize}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
