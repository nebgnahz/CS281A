\section{Problem Formulation}
\label{sec:problem-formulation}

A supervised learning framework for activity recognition consists of data collection, transformation, and the design of adequate learning algorithm. In this section, we first briefly describe our data model (detailed system description and data collection is postponed to Section~\ref{sec:system-data} for completeness). In Section~\ref{subsec: data-transform}, we show how raw data is transformed into feature space. In addition, the problem of feature selection for efficient learning is discussed. In Section~\ref{subsec: learning}, we formulate the learning problem, and propose two methods for a comparative study.  

\subsection{Data Model}
\label{subsec: data-model}
We consider the sensor data model being a 3-dimensional accelerometer. Though gyroscope, magnetic sensor, rotation are also available and our data collection application supports them, for comparison with Pebble, we restrict the dataset to be accelerometer data. From a data analysis point of view, the obtained observations are a set of time series with fine time resolution. Each observation has 3-dimension $x, y, z$. 

We also label the data from a video recording we did when we collect the data. We consider five different activities \{standing, walking, downstairs, upstairs, running\} ({\bf for brevity, we will also use the number $\{1,2,...,5\}$ to represent each activity}). 

\subsection{Data Transformation \& Feature Selection}
\label{subsec: data-transform}

The raw data is a 3-dimensional time series exhibiting non-stationarity with fine time resolution. It is very difficult if not impossible to learn a good classifier that map the raw sensor readings directly to labels/classes. As most of the machine learning task, we face the challenge problem of feature extraction. In previous literature, it is widely acknowledged that a window frame based feature extraction could be adopted since most human activities are approximately periodic in nature. In this paper, we also consider feature extraction within a window frame, however, instead of merely focus on time and frequency domain feature, we proposed to add empirical distribution of frequencies as another categorical feature. This is because intuitively, different activities may induce very different frequency nature of the body. To be specific, we add binned distribution of Fast Fourier Transform (FFT) coefficients for each window as a $d$ dimensional feature, where $d$ is the number of bins. In addition, we calculate the empirical entropy as another feature candidate. As for time domain, we propose to add first order derivative (difference in time series) as an additional feature, the reason for this is the observation that different activities usually have distinguished ``rate of change'' in terms of body movement.

To sum up, we have the following features (also shown in Table~\ref{tab:feature1}):
\begin{itemize}
\item \textbf{Time Domain Features:} In each window, for one particular observation time series, we directly calculate Mean, Variance, and for each 3D streams of a particular sensor, we calculate the Covariance and the Magnitude. We also calculate the discrete first derivative and export the same statistics as features. 
\item \textbf{Frequency Domain Features:} We use Fast Fourier Transform to delve into frequency domain, and export energy and entropy of resulted FFT coefficients in each window.
\end{itemize}

\begin{table}
  \centering
  \begin{tabular}{c|c}
    \hline
    & $\bar{x}, \bar{y}, \bar{z}, var(x), var(y), var(z)$\\
    Time Domain  & $cov(x,y), cov(y,z), cov(z,x)$\\
    &$\sqrt{x^2+y^2+z^2}$\\
    & $x_{t+1}-x_{t}, y_{t+1}-y_{t}, z_{t+1}-z_{t}$\\
    \hline
    Frequency Domain  & $\sum_j w_j^2/N, -\sum_i p_ilog(p_i)$  \\
    \hline
  \end{tabular}
  \caption{Extracted Features}
  \label{tab:feature1}
\end{table}

Hence the transformed data set is a $20$ dimensional tuple, with $19$ features and $1$ label indicating the ground truth of corresponding activity. Note that another information that are implicitly collected is the transition between activities. In fact, the consideration of adding this information or not is going to lead us to two entirely different probabilistic models. Namely, if dynamic transition information is ignored, the problem reduces to common classification problem, and the underlying assumption is that each observation is draw $iid$ from some distribution. While if dynamic transitional information is incorporated in the model, because of the dependency of ``future'' and ``past'', usually local time series model should be considered for continuous measurement, and Markov Chains or semi Markov models should be used to model discrete hidden classes. Actually, the Hidden Markov Model (HMM) is one simple example of this kind. 

People would argue that incorporating additional information should yield better classification results. However, it may not be true in practice. On one hand, a dynamic model like HMM is more complex to train and may has higher parameter estimation error. On the other hand, it is arguable if human activity really exhibits Markov transitions. Granted that transition tendency exist, the transitional matrix may (or for most people)NOT be stationary,which rend HMM unsuitable because it requires stationary transitions to propagate. Of cause non-stationary model could be considered, but we doubt it will be too complex to carry out real parameter estimation and inference work. That's why in our project, we tried both multinomial logistic regression and HMM as machine learning tools for the purpose of activity recognition.  

Last but not least issue concerning the problem at hand is that the features we are using may not be all beneficial in terms of activity recognition. Since our previous feature selection is based mainly on empirical knowledge or intuition, the selected features may not be relevant or there may be redundancy in the feature space. Principle component analysis (PCA) could be used to eliminate redundancy, but transformed features after PCA do not have a clear meaning. In this project, we consider regularized method for statistical feature selection. Particularly, we applied $L1$ regularized logistic regression and check the solution path. 

\subsection{Activity Recognition as Supervised Learning}
\label{subsec: learning}

As an abstraction of above description, our task is to find a function $f: R^{19}\times T \rightarrow \{1,2,3,4,5\}$. If we assume that transition information is not important and consider obtained samples as $iid$ samples from certain distribution, our task is reduced to estimate $f: R^{19} \rightarrow \{1,2,3,4,5\}$. With this approximation, various classification methods are available, such as logistic regression (LR), support vector machine (SVM), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), decision tree (DT), etc. We adopt Multinomial Logistic Regression (MLR) and Hidden Markove Model (HMM) in this project.

%\begin{figure}[p]
%  \begin{center}
%    \includegraphics[width=0.4\textwidth]{C:/Dropbox/281A/figures/logiHmm.png}
%    \caption{Logistis Regression vs. HMM}
%    \label{fig:logiHmm}
%  \end{center}
%\end{figure}

Let's briefly review some key formulation for multinomial logistic regression and hidden markov model. A comprehensive introduction of the theory can be found in Prof.~Jordan's book.

As a generalization of logistic regress for multiclass problems, MLR models the probability of each class $y$ as a Logit function of linear combinations of feature variables $x$. Specifically, assume there are $K$ classes, for $m=1,2,...,K-1$
\begin{equation}
Pr(y_i=m) = \frac{e^{\beta_m^Tx_i}}{1+\sum_{k=1}^{K-1}\beta_k^Tx_i}
\end{equation}
and for $m=K$
\begin{equation}
Pr(y_i=K) = \frac{1}{1+\sum_{k=1}^{K-1}\beta_k^Tx_i}
\end{equation}
which ensures each probability has value between $[0,1]$ and their sum equal to $1$. The model parameters are vectors $\beta_1,\beta_2,...,\beta_{k-1}$. Note that our project, from a machine learning viewpoint consists of two task, which are parameter estimation for training and inference for testing. 

The parameter estimation for logistic regression is a widely studied topic. Usually, various algorithms are available to compute the ML estimation in non-regularized case and MAP estimation in $L2$ regularized case. In fact, for logistic regression without regularization, the ML problem just reads,
\begin{equation}
min_{\beta} \sum_i -logp(y_i|x_i,\beta)
\end{equation}
and with $L2$ norm regularization, we simply add a $L2$ penalty for $beta$,
\begin{equation}\nonumber
min_{\beta} \sum_i -logp(y_i|x_i,\beta) + \lambda \Vert \beta \Vert^2
\end{equation}
the penalty term can also be thought of putting a prior for $\beta$, thus sometimes is called MAP estimation. From a vast pool of such algorithms we find  generalized iterative scaling, Iteratively Reweighted Least Squares (IRLS), L-BFGS (gradient based nonlinear programming), and some specialized coordinate descent algorithms. However, $L2$ norm only regularize parameter ``proportionally'', and usually is depreciated when feature selection is our main purpose. As an alternative, $L1$ norm is used instead of $L2$ with advantages that it tend to push some parameters to be exactly zero, thus favors feature selection. Actually, the improvement here is very similar to the advantages of using LASSO. In our project, we perform both logistic regression without regularization, and with $L1$ regularization as an attempt for feature selection, i.e.
\begin{equation}\nonumber
min_{\beta} \sum_i -logp(y_i|x_i,\beta) + \lambda \Vert \beta \Vert_1
\end{equation}

The inference problem, or in other words, the prediction problem aims at estimate class label $y$ given a new set of observations. In the case of logistic regression, this is simply done by calculating class probability $Pr(y_i=$ based on estimated $\hat{\beta}$, and then choose a proper cut-off probability to assign class labels. 

As is mentioned in last section, a major drawback of common classification tools like Logistic Regression, SVM, QDA, Decision Tree make $iid$ assumption for samples and ignore temporal dependence in the phenomenon. Although most of existing research on activity recognition choose to ignore time dependence, we argue that transitional information may be able to help in that it can ``filter out'' impossible transitions and thus improve accuracy. The challenge for using HMM in our case is the choice of emission distribution. Because we have a relatively high feature dimension, some EDA should be performed before concluding any form of distribution $Pr(x|y)$. We summarized our choice in Table~\ref{table:distribution} and EDA will be provided in later chapters. Note that the choice is only approximately correct, especially for $var(x),var(y),var(z)$, a more proper choice could be matrix Gamma distribution, but the parameter estimation is hard. 
\begin{table}
\begin{center}
\begin{tabular}{c|c
}
      \hline
      $\bar{x},\bar{y},\bar{z}|y$& multivariate Gaussian\\
      \hline
      $var(x),var(y),var(z)|y$ &  multivariate Gaussian\\
      \hline
      $cov(x,y),cov(y,z),cov(z,x)|y$& multivariate Gaussian\\
      \hline
      $\sqrt{x^2+y^2+z^2}|y$& Gamma\\
      \hline
      $x_{t+1}-x_{t},y_{t+1}-y_{t},z_{t+1}-z_{t}|y$ & multivariate Gaussian\\
      \hline
      $\frac{\sum_j w_j^2}{N}|y$& Exponential \\ \hline
      $ -\sum_i p_ilog(p_i)|y$ & Gamma \\
  \hline
\end{tabular}
\end{center}
\caption{Extracted Features Distribution}
\label{table:distribution}
\end{table}


The parameter estimation for HMM in our case is fairly simple, in fact, since we are in a supervised learning case, while training the hidden states are actually observable. The log likelihood is already a ``complete'' likelihood. i.e. in the parameterization
\begin{equation} \nonumber
l(q,y) = log\left\{\pi_{q_0}\prod_{t=1}^{T-1} a_{q_t,q_{t+1}}\prod_{t=0}^T Pr(y_t|q_t,\eta)\right\}
\end{equation}
both $q$ and $y$ are known. The ML estimation can be calculated directly by taking derivatives,
\begin{equation} \nonumber
\hat{a}_{i,j} = \frac{m_{ij}}{\sum_{k=1}^M m_{ij}}
\end{equation}
with $m_{ij}$ defined as in the class, and the parameter estimate for distribution in table (\ref{table:distribution}) can be calculated trivially in each class. For Gaussian and exponential, the results are well known, as for Gamma distribution with parameter $\theta$ and $\alpha$,
\begin{equation}
\hat{\theta} = \frac{1}{\alpha N}\sum_{i=1}^Nx_i
\end{equation}
we can compute $\alpha$ iteratively 
\begin{equation}
\alpha \leftarrow \alpha - \frac{ \ln(\alpha) - \psi(\alpha) - s }{ \frac{1}{\alpha} - \psi^{\prime}(\alpha) }
\end{equation}
with 
\begin{equation} \nonumber
s = \ln{\left(\frac{1}{N}\sum_{i=1}^N x_i\right)} - \frac{1}{N}\sum_{i=1}^N\ln{(x_i)}
\end{equation}
After parameter estimation/training, we use the obtained model for inference/testing. The classification problem is equivalent to estimate hidden state $q$ give observation $y$ and the model parameters. The posterior probability of $q$ is defined as 
\begin{equation} \nonumber
p(q_t^i=1|y,\eta) = \gamma_t^i
\end{equation} 
where backward and forward propagation can be performed to find $\gamma_t^i$
\begin{equation}
\gamma (q_t) = \sum_{q_{t+1}} \frac{\alpha (q_t) a_{q_t,q_{t+1}}}{\sum_{q_t} \alpha (q_t)a_{q_t,q_{t+1}}} \gamma (q_{t+1})
\end{equation}
and
\begin{equation}
\alpha (q_{t+1}) = \sum_{q_t} \alpha (q_t)  a_{q_t,q_{t+1}} p(y_{t+1}|q_{t+1})
\end{equation}

Finally, we pick up a reasonable cut-off probability threshold, e.g. $[\frac{1}{5},...,\frac{1}{5}]$, to assign the class labels for each $q_t$.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
